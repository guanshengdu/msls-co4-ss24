{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":30301,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.axes_grid import ImageGrid\n\nfrom tqdm.notebook import tqdm\nimport time\nimport random\n\nplt.style.use(\"dark_background\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-17T07:14:24.745350Z","iopub.execute_input":"2024-05-17T07:14:24.745864Z","iopub.status.idle":"2024-05-17T07:14:26.343220Z","shell.execute_reply.started":"2024-05-17T07:14:24.745764Z","shell.execute_reply":"2024-05-17T07:14:26.341781Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: \nThe mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"BASE_PATH= \"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:14:38.632653Z","iopub.execute_input":"2024-05-17T07:14:38.633081Z","iopub.status.idle":"2024-05-17T07:14:38.638311Z","shell.execute_reply.started":"2024-05-17T07:14:38.633048Z","shell.execute_reply":"2024-05-17T07:14:38.637071Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"BASE_LEN = 89\nEND_LEN = 4\nEND_MASK_LEN = 9\n\nIMG_SIZE = 512","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:14:42.938965Z","iopub.execute_input":"2024-05-17T07:14:42.939378Z","iopub.status.idle":"2024-05-17T07:14:42.944963Z","shell.execute_reply.started":"2024-05-17T07:14:42.939343Z","shell.execute_reply":"2024-05-17T07:14:42.943658Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Get & Prepare Data","metadata":{}},{"cell_type":"code","source":"data = []\n\nfor dir_ in os.listdir(BASE_PATH):\n    dir_path = os.path.join(BASE_PATH, dir_)\n    if os.path.isdir(dir_path):\n        for filename in os.listdir(dir_path):\n            img_path = os.path.join(dir_path, filename)\n            data.append([dir_, img_path])\n    else:\n        print(f\"[INFO] This is not a dir --> {dir_path}\")\n        \ndf = pd.DataFrame(data, columns=[\"dir_name\", \"image_path\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:14:47.198430Z","iopub.execute_input":"2024-05-17T07:14:47.198880Z","iopub.status.idle":"2024-05-17T07:14:50.188398Z","shell.execute_reply.started":"2024-05-17T07:14:47.198845Z","shell.execute_reply":"2024-05-17T07:14:50.187299Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[INFO] This is not a dir --> /kaggle/input/lgg-mri-segmentation/kaggle_3m/README.md\n[INFO] This is not a dir --> /kaggle/input/lgg-mri-segmentation/kaggle_3m/data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_imgs = df[~df[\"image_path\"].str.contains(\"mask\")]\ndf_masks = df[df[\"image_path\"].str.contains(\"mask\")]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:15:05.979776Z","iopub.execute_input":"2024-05-17T07:15:05.980178Z","iopub.status.idle":"2024-05-17T07:15:06.008530Z","shell.execute_reply.started":"2024-05-17T07:15:05.980148Z","shell.execute_reply":"2024-05-17T07:15:06.007241Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"imgs = sorted(df_imgs[\"image_path\"].values, key= lambda x: int(x[BASE_LEN: -END_LEN]))\nmasks = sorted(df_masks[\"image_path\"].values, key=lambda x: int(x[BASE_LEN: -END_MASK_LEN]))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:15:08.396471Z","iopub.execute_input":"2024-05-17T07:15:08.396946Z","iopub.status.idle":"2024-05-17T07:15:08.408037Z","shell.execute_reply.started":"2024-05-17T07:15:08.396863Z","shell.execute_reply":"2024-05-17T07:15:08.407097Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# sanity check\nidx = random.randint(0, len(imgs)-1)\nprint(f\"This image *{imgs[idx]}*\\n Belongs to the mask *{masks[idx]}*\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:15:10.325786Z","iopub.execute_input":"2024-05-17T07:15:10.326199Z","iopub.status.idle":"2024-05-17T07:15:10.332595Z","shell.execute_reply.started":"2024-05-17T07:15:10.326166Z","shell.execute_reply":"2024-05-17T07:15:10.331356Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"This image */kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_23.tif*\n Belongs to the mask */kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_23_mask.tif*\n","output_type":"stream"}]},{"cell_type":"code","source":"# final dataframe\ndff = pd.DataFrame({\"patient\": df_imgs.dir_name.values,\n                   \"image_path\": imgs,\n                   \"mask_path\": masks})\n\ndff.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:15:14.796746Z","iopub.execute_input":"2024-05-17T07:15:14.797149Z","iopub.status.idle":"2024-05-17T07:15:14.818536Z","shell.execute_reply.started":"2024-05-17T07:15:14.797118Z","shell.execute_reply":"2024-05-17T07:15:14.817376Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                 patient                                         image_path  \\\n0  TCGA_DU_7010_19860307  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n1  TCGA_DU_7010_19860307  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n2  TCGA_DU_7010_19860307  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n3  TCGA_DU_7010_19860307  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n4  TCGA_DU_7010_19860307  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n\n                                           mask_path  \n0  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n1  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n2  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n3  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n4  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dff\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T07:15:22.971442Z","iopub.execute_input":"2024-05-17T07:15:22.971898Z","iopub.status.idle":"2024-05-17T07:15:22.987919Z","shell.execute_reply.started":"2024-05-17T07:15:22.971861Z","shell.execute_reply":"2024-05-17T07:15:22.986833Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                    patient  \\\n0     TCGA_DU_7010_19860307   \n1     TCGA_DU_7010_19860307   \n2     TCGA_DU_7010_19860307   \n3     TCGA_DU_7010_19860307   \n4     TCGA_DU_7010_19860307   \n...                     ...   \n3924  TCGA_DU_7306_19930512   \n3925  TCGA_DU_7306_19930512   \n3926  TCGA_DU_7306_19930512   \n3927  TCGA_DU_7306_19930512   \n3928  TCGA_DU_7306_19930512   \n\n                                             image_path  \\\n0     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n1     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n2     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n3     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n4     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n...                                                 ...   \n3924  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n3925  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n3926  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n3927  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n3928  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...   \n\n                                              mask_path  \n0     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n1     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n2     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n3     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n4     /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n...                                                 ...  \n3924  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n3925  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n3926  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n3927  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n3928  /kaggle/input/lgg-mri-segmentation/kaggle_3m/T...  \n\n[3929 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TCGA_DU_7010_19860307</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3924</th>\n      <td>TCGA_DU_7306_19930512</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>3925</th>\n      <td>TCGA_DU_7306_19930512</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>3926</th>\n      <td>TCGA_DU_7306_19930512</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>3927</th>\n      <td>TCGA_DU_7306_19930512</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n    <tr>\n      <th>3928</th>\n      <td>TCGA_DU_7306_19930512</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n      <td>/kaggle/input/lgg-mri-segmentation/kaggle_3m/T...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3929 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def pos_neg_diagnosis(mask_path):\n    val = np.max(cv2.imread(mask_path))\n    if val > 0: return 1\n    else: return 0","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:06:34.541331Z","iopub.execute_input":"2022-12-06T13:06:34.541712Z","iopub.status.idle":"2022-12-06T13:06:34.550825Z","shell.execute_reply.started":"2022-12-06T13:06:34.541678Z","shell.execute_reply":"2022-12-06T13:06:34.549719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dff[\"diagnosis\"] = dff[\"mask_path\"].apply(lambda x: pos_neg_diagnosis(x))\n\ndff.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:06:34.560228Z","iopub.execute_input":"2022-12-06T13:06:34.560652Z","iopub.status.idle":"2022-12-06T13:06:56.563319Z","shell.execute_reply.started":"2022-12-06T13:06:34.560614Z","shell.execute_reply":"2022-12-06T13:06:56.562245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dff.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:06:56.564653Z","iopub.execute_input":"2022-12-06T13:06:56.565106Z","iopub.status.idle":"2022-12-06T13:06:56.571959Z","shell.execute_reply.started":"2022-12-06T13:06:56.56507Z","shell.execute_reply":"2022-12-06T13:06:56.570967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Amount of patients: \", len(set(dff.patient)))\nprint(\"Amount of records: \", len(dff))","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:06:56.573485Z","iopub.execute_input":"2022-12-06T13:06:56.574746Z","iopub.status.idle":"2022-12-06T13:06:56.582836Z","shell.execute_reply.started":"2022-12-06T13:06:56.574709Z","shell.execute_reply":"2022-12-06T13:06:56.581703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"!pip install albumentations==0.4.6","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:06:56.5842Z","iopub.execute_input":"2022-12-06T13:06:56.585275Z","iopub.status.idle":"2022-12-06T13:07:10.805407Z","shell.execute_reply.started":"2022-12-06T13:06:56.58524Z","shell.execute_reply":"2022-12-06T13:07:10.804229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2, ToTensor\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:10.808017Z","iopub.execute_input":"2022-12-06T13:07:10.808468Z","iopub.status.idle":"2022-12-06T13:07:13.90032Z","shell.execute_reply.started":"2022-12-06T13:07:10.808424Z","shell.execute_reply":"2022-12-06T13:07:13.899272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:13.901831Z","iopub.execute_input":"2022-12-06T13:07:13.902692Z","iopub.status.idle":"2022-12-06T13:07:14.032491Z","shell.execute_reply.started":"2022-12-06T13:07:13.902653Z","shell.execute_reply":"2022-12-06T13:07:14.031198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BrainMRIDataset:\n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = cv2.imread(self.df.iloc[idx, 1])\n        mask = cv2.imread(self.df.iloc[idx, 2], 0)\n        \n        augmented = self.transforms(image=image,\n                                   mask=mask)\n        \n        image = augmented[\"image\"]\n        mask = augmented[\"mask\"]\n        \n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:14.034269Z","iopub.execute_input":"2022-12-06T13:07:14.034948Z","iopub.status.idle":"2022-12-06T13:07:14.052612Z","shell.execute_reply.started":"2022-12-06T13:07:14.034905Z","shell.execute_reply":"2022-12-06T13:07:14.051749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATCH_SIZE = 128\n\ntransforms = A.Compose([\n    A.Resize(width = PATCH_SIZE, height = PATCH_SIZE, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.Transpose(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n\n    A.Normalize(p=1.0),\n    ToTensor(),\n    \n])","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:14.054917Z","iopub.execute_input":"2022-12-06T13:07:14.05639Z","iopub.status.idle":"2022-12-06T13:07:14.064345Z","shell.execute_reply.started":"2022-12-06T13:07:14.056324Z","shell.execute_reply":"2022-12-06T13:07:14.063238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data and DataLoaders","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(dff, stratify=dff.diagnosis, test_size=0.1)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\n\ntrain_df, test_df = train_test_split(train_df, stratify=train_df.diagnosis, test_size=0.12)\ntrain_df = train_df.reset_index(drop=True)\n\nprint(f\"Train: {train_df.shape} \\nVal: {val_df.shape} \\nTest: {test_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:14.066699Z","iopub.execute_input":"2022-12-06T13:07:14.068635Z","iopub.status.idle":"2022-12-06T13:07:14.08694Z","shell.execute_reply.started":"2022-12-06T13:07:14.068593Z","shell.execute_reply":"2022-12-06T13:07:14.085772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BrainMRIDataset(train_df, transforms=transforms)\ntrain_dataloader = DataLoader(train_dataset, batch_size=26, num_workers=2, shuffle=True)\n\nval_dataset = BrainMRIDataset(val_df, transforms=transforms)\nval_dataloader = DataLoader(val_dataset, batch_size=26, num_workers=2, shuffle=True)\n\ntest_dataset = BrainMRIDataset(test_df, transforms=transforms)\ntest_dataloader = DataLoader(test_dataset, batch_size=26, num_workers=2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:14.088536Z","iopub.execute_input":"2022-12-06T13:07:14.089137Z","iopub.status.idle":"2022-12-06T13:07:14.096904Z","shell.execute_reply.started":"2022-12-06T13:07:14.089099Z","shell.execute_reply":"2022-12-06T13:07:14.095683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_aug(inputs, nrows=5, ncols=5, norm=False):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(wspace=0., hspace=0.)\n    i_ = 0\n    \n    if len(inputs) > 25:\n        inputs = inputs[:25]\n        \n    for idx in range(len(inputs)):\n    \n        # normalization\n        if norm:           \n            img = inputs[idx].numpy().transpose(1,2,0)\n            mean = [0.485, 0.456, 0.406]\n            std = [0.229, 0.224, 0.225] \n            img = (img*std+mean).astype(np.float32)\n            \n        else:\n            img = inputs[idx].numpy().astype(np.float32)\n            img = img[0,:,:]\n        \n        plt.subplot(nrows, ncols, i_+1)\n        plt.imshow(img); \n        plt.axis('off')\n \n        i_ += 1\n        \n    return plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:14.09873Z","iopub.execute_input":"2022-12-06T13:07:14.100171Z","iopub.status.idle":"2022-12-06T13:07:14.110719Z","shell.execute_reply.started":"2022-12-06T13:07:14.100119Z","shell.execute_reply":"2022-12-06T13:07:14.109626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, masks = next(iter(train_dataloader))\nprint(images.shape, masks.shape)\n\nshow_aug(images)\nshow_aug(masks, norm=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:14.112176Z","iopub.execute_input":"2022-12-06T13:07:14.112832Z","iopub.status.idle":"2022-12-06T13:07:17.257368Z","shell.execute_reply.started":"2022-12-06T13:07:14.112794Z","shell.execute_reply":"2022-12-06T13:07:17.256278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attention U-Net","metadata":{}},{"cell_type":"markdown","source":"## Model Blocks","metadata":{}},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super().__init__()\n        self.conv = nn.Sequential(\n                                  nn.Conv2d(ch_in, ch_out,\n                                            kernel_size=3, stride=1,\n                                            padding=1, bias=True),\n                                  nn.BatchNorm2d(ch_out),\n                                  nn.ReLU(inplace=True),\n                                  nn.Conv2d(ch_out, ch_out,\n                                            kernel_size=3, stride=1,\n                                            padding=1, bias=True),\n                                  nn.BatchNorm2d(ch_out),\n                                  nn.ReLU(inplace=True),\n        )\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:17.258951Z","iopub.execute_input":"2022-12-06T13:07:17.260623Z","iopub.status.idle":"2022-12-06T13:07:17.267684Z","shell.execute_reply.started":"2022-12-06T13:07:17.260581Z","shell.execute_reply":"2022-12-06T13:07:17.267037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UpConvBlock(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super().__init__()\n        self.up = nn.Sequential(\n                                nn.Upsample(scale_factor=2),\n                                nn.Conv2d(ch_in, ch_out,\n                                         kernel_size=3,stride=1,\n                                         padding=1, bias=True),\n                                nn.BatchNorm2d(ch_out),\n                                nn.ReLU(inplace=True),\n        )\n        \n    def forward(self, x):\n        x = x = self.up(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:17.26965Z","iopub.execute_input":"2022-12-06T13:07:17.270468Z","iopub.status.idle":"2022-12-06T13:07:17.28093Z","shell.execute_reply.started":"2022-12-06T13:07:17.270432Z","shell.execute_reply":"2022-12-06T13:07:17.280196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionBlock(nn.Module):\n    def __init__(self, f_g, f_l, f_int):\n        super().__init__()\n        \n        self.w_g = nn.Sequential(\n                                nn.Conv2d(f_g, f_int,\n                                         kernel_size=1, stride=1,\n                                         padding=0, bias=True),\n                                nn.BatchNorm2d(f_int)\n        )\n        \n        self.w_x = nn.Sequential(\n                                nn.Conv2d(f_l, f_int,\n                                         kernel_size=1, stride=1,\n                                         padding=0, bias=True),\n                                nn.BatchNorm2d(f_int)\n        )\n        \n        self.psi = nn.Sequential(\n                                nn.Conv2d(f_int, 1,\n                                         kernel_size=1, stride=1,\n                                         padding=0,  bias=True),\n                                nn.BatchNorm2d(1),\n                                nn.Sigmoid(),\n        )\n        \n        self.relu = nn.ReLU(inplace=True)\n        \n    def forward(self, g, x):\n        g1 = self.w_g(g)\n        x1 = self.w_x(x)\n        psi = self.relu(g1+x1)\n        psi = self.psi(psi)\n        \n        return psi*x","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:17.282464Z","iopub.execute_input":"2022-12-06T13:07:17.283183Z","iopub.status.idle":"2022-12-06T13:07:17.297407Z","shell.execute_reply.started":"2022-12-06T13:07:17.283148Z","shell.execute_reply":"2022-12-06T13:07:17.296372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class AttentionUNet(nn.Module):\n    def __init__(self, n_classes=1, in_channel=3, out_channel=1):\n        super().__init__() \n        \n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.conv1 = ConvBlock(ch_in=in_channel, ch_out=64)\n        self.conv2 = ConvBlock(ch_in=64, ch_out=128)\n        self.conv3 = ConvBlock(ch_in=128, ch_out=256)\n        self.conv4 = ConvBlock(ch_in=256, ch_out=512)\n        self.conv5 = ConvBlock(ch_in=512, ch_out=1024)\n        \n        self.up5 = UpConvBlock(ch_in=1024, ch_out=512)\n        self.att5 = AttentionBlock(f_g=512, f_l=512, f_int=256)\n        self.upconv5 = ConvBlock(ch_in=1024, ch_out=512)\n        \n        self.up4 = UpConvBlock(ch_in=512, ch_out=256)\n        self.att4 = AttentionBlock(f_g=256, f_l=256, f_int=128)\n        self.upconv4 = ConvBlock(ch_in=512, ch_out=256)\n        \n        self.up3 = UpConvBlock(ch_in=256, ch_out=128)\n        self.att3 = AttentionBlock(f_g=128, f_l=128, f_int=64)\n        self.upconv3 = ConvBlock(ch_in=256, ch_out=128)\n        \n        self.up2 = UpConvBlock(ch_in=128, ch_out=64)\n        self.att2 = AttentionBlock(f_g=64, f_l=64, f_int=32)\n        self.upconv2 = ConvBlock(ch_in=128, ch_out=64)\n        \n        self.conv_1x1 = nn.Conv2d(64, out_channel,\n                                  kernel_size=1, stride=1, padding=0)\n        \n    def forward(self, x):\n        # encoder\n        x1 = self.conv1(x)\n        \n        x2 = self.maxpool(x1)\n        x2 = self.conv2(x2)\n        \n        x3 = self.maxpool(x2)\n        x3 = self.conv3(x3)\n        \n        x4 = self.maxpool(x3)\n        x4 = self.conv4(x4)\n        \n        x5 = self.maxpool(x4)\n        x5 = self.conv5(x5)\n        \n        # decoder + concat\n        d5 = self.up5(x5)\n        x4 = self.att5(g=d5, x=x4)\n        d5 = torch.concat((x4, d5), dim=1)\n        d5 = self.upconv5(d5)\n        \n        d4 = self.up4(d5)\n        x3 = self.att4(g=d4, x=x3)\n        d4 = torch.concat((x3, d4), dim=1)\n        d4 = self.upconv4(d4)\n        \n        d3 = self.up3(d4)\n        x2 = self.att3(g=d3, x=x2)\n        d3 = torch.concat((x2, d3), dim=1)\n        d3 = self.upconv3(d3)\n        \n        d2 = self.up2(d3)\n        x1 = self.att2(g=d2, x=x1)\n        d2 = torch.concat((x1, d2), dim=1)\n        d2 = self.upconv2(d2)\n        \n        d1 = self.conv_1x1(d2)\n        \n        return d1","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:17.299658Z","iopub.execute_input":"2022-12-06T13:07:17.300268Z","iopub.status.idle":"2022-12-06T13:07:17.317878Z","shell.execute_reply.started":"2022-12-06T13:07:17.300228Z","shell.execute_reply":"2022-12-06T13:07:17.316902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention_unet = AttentionUNet(n_classes=1).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:17.320658Z","iopub.execute_input":"2022-12-06T13:07:17.321534Z","iopub.status.idle":"2022-12-06T13:07:21.086727Z","shell.execute_reply.started":"2022-12-06T13:07:17.321507Z","shell.execute_reply":"2022-12-06T13:07:21.085552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check sanity\noutput = torch.randn(1,3,256,256).to(device)\noutput.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:07:21.08848Z","iopub.execute_input":"2022-12-06T13:07:21.08888Z","iopub.status.idle":"2022-12-06T13:07:21.100746Z","shell.execute_reply.started":"2022-12-06T13:07:21.088839Z","shell.execute_reply":"2022-12-06T13:07:21.099228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation Metric","metadata":{}},{"cell_type":"code","source":"def dice_coef_metric(inputs, target):\n    intersection = 2.0 * (target*inputs).sum()\n    union = target.sum() + inputs.sum()\n    if target.sum() == 0 and inputs.sum() == 0:\n        return 1.0 \n    return intersection/union","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:17:15.537253Z","iopub.execute_input":"2022-12-06T13:17:15.538201Z","iopub.status.idle":"2022-12-06T13:17:15.544387Z","shell.execute_reply.started":"2022-12-06T13:17:15.538162Z","shell.execute_reply":"2022-12-06T13:17:15.542996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation Loss","metadata":{}},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n        \n        return 1 - dice","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:17:15.827267Z","iopub.execute_input":"2022-12-06T13:17:15.827942Z","iopub.status.idle":"2022-12-06T13:17:15.837316Z","shell.execute_reply.started":"2022-12-06T13:17:15.827906Z","shell.execute_reply":"2022-12-06T13:17:15.836382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sanity check\nDiceLoss()(torch.tensor([0.7, 1., 1.]), \n              torch.tensor([1.,1.,1.]))","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:17:16.00241Z","iopub.execute_input":"2022-12-06T13:17:16.002722Z","iopub.status.idle":"2022-12-06T13:17:16.01302Z","shell.execute_reply.started":"2022-12-06T13:17:16.002695Z","shell.execute_reply":"2022-12-06T13:17:16.011777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_model(model_name, model, train_loader, val_loader, train_loss, optimizer, lr_scheduler, num_epochs):\n    print(f\"[INFO] Model is initializing... {model_name}\")\n    \n    loss_history = []\n    train_history = []\n    val_history = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        \n        losses = []\n        train_iou = []\n        \n        for i_step, (data, target) in enumerate(tqdm(train_loader)):\n            data = data.to(device)\n            target = target.to(device)\n            \n            outputs = model(data)\n            \n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n            \n            train_dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            \n            loss = train_loss(outputs, target)\n            \n            losses.append(loss.item())\n            train_iou.append(train_dice)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        val_mean_iou = compute_iou(model, val_loader)\n        \n        loss_history.append(np.array(losses).mean())\n        train_history.append(np.array(train_iou).mean())\n        val_history.append(val_mean_iou)\n        \n        print(\"Epoch [%d]\" % (epoch))\n        print(\"Mean loss on train:\", np.array(losses).mean(), \n              \"\\nMean DICE on train:\", np.array(train_iou).mean(), \n              \"\\nMean DICE on validation:\", val_mean_iou)\n        \n    return loss_history, train_history, val_history","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:17:16.314589Z","iopub.execute_input":"2022-12-06T13:17:16.314912Z","iopub.status.idle":"2022-12-06T13:17:16.326276Z","shell.execute_reply.started":"2022-12-06T13:17:16.314884Z","shell.execute_reply":"2022-12-06T13:17:16.325044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_iou(model, loader, threshold=0.3):\n    valloss = 0\n    \n    with torch.no_grad():\n\n        for i_step, (data, target) in enumerate(loader):\n            \n            data = data.to(device)\n            target = target.to(device)\n            \n            outputs = model(data)\n\n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < threshold)] = 0.0\n            out_cut[np.nonzero(out_cut >= threshold)] = 1.0\n            picloss = dice_coef_metric(out_cut, target.data.cpu().numpy())\n            valloss += picloss\n\n    return valloss / i_step","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:17:16.497698Z","iopub.execute_input":"2022-12-06T13:17:16.498316Z","iopub.status.idle":"2022-12-06T13:17:16.505812Z","shell.execute_reply.started":"2022-12-06T13:17:16.498275Z","shell.execute_reply":"2022-12-06T13:17:16.504718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = torch.optim.Adamax(attention_unet.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:17:16.945523Z","iopub.execute_input":"2022-12-06T13:17:16.945891Z","iopub.status.idle":"2022-12-06T13:17:16.953102Z","shell.execute_reply.started":"2022-12-06T13:17:16.94586Z","shell.execute_reply":"2022-12-06T13:17:16.95202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nnum_ep = 50\n# after 30 does not improve much\n\naun_lh, aun_th, aun_vh = train_model(\"Attention UNet\", attention_unet, train_dataloader, val_dataloader, DiceLoss(), opt, False, num_ep)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T13:17:17.270905Z","iopub.execute_input":"2022-12-06T13:17:17.271747Z","iopub.status.idle":"2022-12-06T14:40:01.144425Z","shell.execute_reply.started":"2022-12-06T13:17:17.271712Z","shell.execute_reply":"2022-12-06T14:40:01.143208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_model_history(model_name,\n                        train_history, val_history, \n                        num_epochs):\n    \n    x = np.arange(num_epochs)\n\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_history, label='train dice', lw=3, c=\"springgreen\")\n    plt.plot(x, val_history, label='validation dice', lw=3, c=\"deeppink\")\n\n    plt.title(f\"{model_name}\", fontsize=15)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=15)\n    plt.ylabel(\"DICE\", fontsize=15)\n\n    fn = str(int(time.time())) + \".png\"\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:40:18.618603Z","iopub.execute_input":"2022-12-06T14:40:18.618981Z","iopub.status.idle":"2022-12-06T14:40:18.626757Z","shell.execute_reply.started":"2022-12-06T14:40:18.618944Z","shell.execute_reply":"2022-12-06T14:40:18.625667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_history(\"Attention U-Net\", aun_th, aun_vh, num_ep)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:40:18.835216Z","iopub.execute_input":"2022-12-06T14:40:18.835848Z","iopub.status.idle":"2022-12-06T14:40:19.262848Z","shell.execute_reply.started":"2022-12-06T14:40:18.835815Z","shell.execute_reply":"2022-12-06T14:40:19.260484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(num_ep), aun_lh)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:40:30.456235Z","iopub.execute_input":"2022-12-06T14:40:30.457269Z","iopub.status.idle":"2022-12-06T14:40:30.658638Z","shell.execute_reply.started":"2022-12-06T14:40:30.457229Z","shell.execute_reply":"2022-12-06T14:40:30.657707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_iou = compute_iou(attention_unet, test_dataloader)\nprint(f\"\"\"Attention U-Net\\nMean IoU of the test images - {np.around(test_iou, 2)*100}%\"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:40:35.414982Z","iopub.execute_input":"2022-12-06T14:40:35.415365Z","iopub.status.idle":"2022-12-06T14:40:39.635212Z","shell.execute_reply.started":"2022-12-06T14:40:35.415313Z","shell.execute_reply":"2022-12-06T14:40:39.633953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Different Loss Functions and Comparisons\n## For 5 Epochs","metadata":{}},{"cell_type":"code","source":"ALPHA = 0.5\nBETA = 0.5\nGAMMA = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(FocalLoss, self).__init__()\n\n    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n        \n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        #first compute binary cross-entropy \n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        BCE_EXP = torch.exp(-BCE)\n        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n                       \n        return focal_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FocalTverskyLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(FocalTverskyLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        #True Positives, False Positives & False Negatives\n        TP = (inputs * targets).sum()    \n        FP = ((1-targets) * inputs).sum()\n        FN = (targets * (1-inputs)).sum()\n        \n        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n        FocalTversky = (1 - Tversky)**gamma\n                       \n        return FocalTversky","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = scores.view(-1)\n    labels = labels.view(-1)\n    if ignore is None:\n        return scores, labels\n    valid = (labels != ignore)\n    vscores = scores[valid]\n    vlabels = labels[valid]\n    return vscores, vlabels\n\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    p = len(gt_sorted)\n    gts = gt_sorted.sum()\n    intersection = gts - gt_sorted.float().cumsum(0)\n    union = gts + (1 - gt_sorted).float().cumsum(0)\n    jaccard = 1. - intersection / union\n    if p > 1: # cover 1-pixel case\n        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n    return jaccard\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n                          for log, lab in zip(logits, labels))\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n    if len(labels) == 0:\n        # only void pixels, the gradients should be 0\n        return logits.sum() * 0.\n    signs = 2. * labels.float() - 1.\n    errors = (1. - logits * Variable(signs))\n    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n    perm = perm.data\n    gt_sorted = labels[perm]\n    grad = lovasz_grad(gt_sorted)\n    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n    return loss\n\n#=====\n#Multi-class Lovasz loss\n#=====\n\ndef lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n      per_image: compute the loss per image instead of per batch\n      ignore: void class labels\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)\n                          for prob, lab in zip(probas, labels))\n    else:\n        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)\n    return loss\n\n\ndef lovasz_softmax_flat(probas, labels, classes='present'):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n    \"\"\"\n    if probas.numel() == 0:\n        # only void pixels, the gradients should be 0\n        return probas * 0.\n    C = probas.size(1)\n    losses = []\n    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n    for c in class_to_sum:\n        fg = (labels == c).float() # foreground for class c\n        if (classes is 'present' and fg.sum() == 0):\n            continue\n        if C == 1:\n            if len(classes) > 1:\n                raise ValueError('Sigmoid output possible only with 1 class')\n            class_pred = probas[:, 0]\n        else:\n            class_pred = probas[:, c]\n        errors = (Variable(fg) - class_pred).abs()\n        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n        perm = perm.data\n        fg_sorted = fg[perm]\n        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n    return mean(losses)\n\nclass LovaszHingeLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(LovaszHingeLoss, self).__init__()\n\n    def forward(self, inputs, targets):\n        inputs = F.sigmoid(inputs)    \n        Lovasz = lovasz_hinge(inputs, targets, per_image=False)                       \n        return Lovasz","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Focal Loss","metadata":{}},{"cell_type":"code","source":"%%time\nnum_ep = 5\n\naun_lh2, aun_th2, aun_vh2 = train_model(\"Attention UNet\", attention_unet, train_dataloader, val_dataloader, FocalLoss(), opt, False, num_ep)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_history(\"Focal Loss Attention U-Net\", aun_th2, aun_vh2, num_ep)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(num_ep), aun_lh2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Focal Tversky Loss","metadata":{}},{"cell_type":"code","source":"%%time\nnum_ep = 5\n\naun_lh3, aun_th3, aun_vh3 = train_model(\"Attention UNet\", attention_unet, train_dataloader, val_dataloader, FocalTverskyLoss(), opt, False, num_ep)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_history(\"Focal Tversky Loss Attention U-Net\", aun_th3, aun_vh3, num_ep)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(num_ep), aun_lh3)","metadata":{},"execution_count":null,"outputs":[]}]}
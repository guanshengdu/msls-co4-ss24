{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Segmentation â€“ Basics**\n",
    "\n",
    "In this notebook on segmentation, we will learn how to segment hematological images using different approaches. In a first step, we try to segment the cells using simple thresholding.\n",
    "\n",
    "Note that several of the topics discussed in this notebook are also covered \n",
    "in this insightful tutorial for this ImageJ/Fiji plugin [MorphoLibJ](https://imagej.net/plugins/morpholibj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Preparations**\n",
    "\n",
    "Let's begin with the usual preparatory steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import PIL\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "#Â Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable this line if you want to use the interactive widgets\n",
    "# It requires the ipympl package to be installed.\n",
    "#%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, too, we will work with the same images as before in the notebook on pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "img1 = cv.imread(\"../data/images/hematology-baso1.jpg\", cv.IMREAD_COLOR)\n",
    "img2 = cv.imread(\"../data/images/hematology-baso2.jpg\", cv.IMREAD_COLOR)\n",
    "img3 = cv.imread(\"../data/images/hematology-blast1.jpg\", cv.IMREAD_COLOR)\n",
    "\n",
    "img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "img3 = cv.cvtColor(img3, cv.COLOR_BGR2RGB)\n",
    "\n",
    "tools.show_image_chain([img1, img2, img3], titles=[\"img1\", \"img2\", \"img3\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Thresholding**\n",
    "\n",
    "We can segment images using basic thresholding techniques. In this example, we explore the different thresholding methods available in OpenCV:\n",
    "- Simple thresholding (use [`cv.threshold()`](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57), use flag `cv.THRESH_BINARY` or `cv.THRESH_BINARY_INV`)\n",
    "- Adaptive thresholding (use [`cv.adaptiveThreshold()`](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#ga72b913f352e4a1b1b397736707afcde3))\n",
    "- Otsu's thresholding (use [`cv.threshold()`](https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57), use flags `cv.THRESH_BINARY+cv.THRESH_OTSU`)\n",
    "\n",
    "Thresholding segments pixels into either foreground or background based on their intensity values. Thresholding is therefore an instance of *binary* image segmentation. The algorithms work by comparing the intensity values of the pixels in an image with a threshold value. Pixels with intensity values greater than the threshold are classified as foreground pixels, while pixels with intensity values less than the threshold are classified as background pixels. The threshold value can be set manually or determined automatically.\n",
    "\n",
    "As preparation, please read this documentation on segmentation methods in OpenCV: [Link](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Choose here the image to work with\n",
    "img = img1\n",
    "\n",
    "# 1) Summarize the three different thresholding techniques in own words. Which methods\n",
    "#    use a global threshold, which ones apply a local threshold? \n",
    "\n",
    "# 2) Develop a strategy to segment the white blood cells (purple), the red blood cells \n",
    "# (red) and the background (white/gray). You may want to exploit the fact that we have\n",
    "# colors to work with:\n",
    "tools.show_image_chain([img[:,:,0], img[:,:,1], img[:,:,2]], titles=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "# 3) Identify the different regions using thresholding\n",
    "mask_wbc = ...\n",
    "mask_rbc = ...\n",
    "mask_bg = ...\n",
    "\n",
    "# 4) Visualize the masks. Idea: combine the three masks into an RGB image.\n",
    "mask_seg = ...\n",
    "\n",
    "# 5) Discuss your results. What could be improved? What are the limitations of this \n",
    "#    approach? Are the masks mutually exclusive? Are they accurate?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## **Color clustering**\n",
    "\n",
    "Instead of segmenting the image, we could also try to classify the different regions. For this, we can use a clustering algorithm such as [K-means](https://en.wikipedia.org/wiki/K-means_clustering). The algorithm works by classifying pixels in an image into clusters based on their color similarity. The similarity is measured using the (Eucledian or non-Euclidean) distance between the pixel values. The algorithm iteratively assigns pixels to clusters based on their distance to the cluster centers and updates the cluster centers based on the mean of the pixels in the cluster. The process continues until the cluster centers converge. See here for a nice [visualization](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)) of the algorithm.\n",
    "\n",
    "As a preparatory step, have a look at the following two tutorials:\n",
    "- Machine Learning Master / Jason Brownlee on [color quantization](https://machinelearningmastery.com/k-means-clustering-in-opencv-and-application-for-color-quantization/)\n",
    "- Shubhang Agrawal / Image segmentation using [k-means clustering](https://medium.com/swlh/image-segmentation-using-k-means-clustering-46a60488ae71) (the tutorial has a few flaws, please excuse). \n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "Resources:\n",
    "# Nice way of depicting the bars\n",
    "https://pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/\n",
    "# OpenCV\n",
    "https://docs.opencv.org/3.4/d1/d5c/tutorial_py_kmeans_opencv.html\n",
    "# Machine Learning Mastery\n",
    "https://machinelearningmastery.com/k-means-clustering-in-opencv-and-application-for-color-quantization/\n",
    "# Watershed\n",
    "https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html\n",
    "# Segmentation with Skimage \n",
    "https://github.com/ipython-books/cookbook-2nd-code/blob/master/chapter11_image/03_segmentation.ipynb\n",
    "# Combination between thresholding and color clustering\n",
    "https://towardsdatascience.com/image-color-segmentation-by-k-means-clustering-algorithm-5792e563f26e\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Choose here the image to work with\n",
    "img = img1\n",
    "\n",
    "# 1) Reshape the color pixels into a Mx3 matrix (M: number of pixels)\n",
    "#    and convert the data type to float32.\n",
    "data = img.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "# 2) Apply the K-means algorithm to the data. Use the cv.kmeans function.\n",
    "#    Choose the number of clusters K=3.\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 3\n",
    "ret, label, centers = cv.kmeans(data, K, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "# label contains the cluster index for each pixel\n",
    "# centers contains the cluster centers (colors!)\n",
    "\n",
    "# 3) Reshape and convert the data back to uint8\n",
    "img_seg = ...\n",
    "\n",
    "# 4) Visualize the segmented image\n",
    "tools.show_image_pair(img, img_seg, title1=\"Original\", title2=\"Segmented\")\n",
    "\n",
    "# 5) Repeat the process for a different color space (e.g. HSV)\n",
    "#    Is the clustering more robust? Why? When does this approach fail?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Watershed algorithm for segmentation**\n",
    "\n",
    "The watershed algorithm is a powerful tool for image segmentation. It is based on\n",
    "the concept of watershed lines, which are lines that separate different regions in\n",
    "an image. The algorithm works by flooding the image with \"water\" from different\n",
    "regions (or seed points) and letting the water flow until it reaches a boundary. \n",
    "The watershed lines are then defined as the boundaries between the regions where\n",
    "the water meets. The algorithm can be used to segment images into different regions\n",
    "based on the intensity or color of the pixels. It is particularly useful for\n",
    "segmenting images with complex shapes and structures.\n",
    "\n",
    "Our dataset structurally resembles the image used in this [tutorial](https://learnopencv.com/k-means-clustering-in-opencv-cpp-python/). \n",
    "Let's use this demo naively to segment our image using the watershed method. \n",
    "\n",
    "The tutorial uses the following strategy: \n",
    "1. Convert the image into binary mask using thresholding\n",
    "2. Apply so-called morphological operations\\* to remove noise, and to separate the objects. We also use similar operations to identify regions that most likely represent the background of our scene.\n",
    "3. with the next steps we aim to identify the seed points for the watershed algorithm\n",
    "   1. Apply the distance transform\\*\\* to the binary image, which measures the distance of each pixel to the nearest zero pixel.\n",
    "   2. Apply a threshold to the distance-transformed image to obtain blobs of pixels that are located close to the centers of our objects of interest.\n",
    "   3. Use the connected components\\*\\*\\* algorithm to identify and enumerate the different seed points. This turns \n",
    "  the binary mask into a mask with (integer) labeled objects.\n",
    "   4. In a last step, mark the background seed regions (see step 2.) with label 0.\n",
    "4. Fiinally, apply the watershed algorithm to segment the regions of interest.\n",
    "5. Visualize the segmented image.\n",
    "\n",
    "\n",
    "### \\* **Morphological operations** \n",
    "Morphological operations are a set of operations that are used to analyze and manipulate\n",
    "the shape of objects in an image. Although the operations are defined also for other types\n",
    "of images, they are most commonly used in binary images. The operations involve structuring\n",
    "elements (kernels) that are used to probe the image and modify the pixel values based on the\n",
    "interaction between the kernel and the image. The most common morphological operations are\n",
    "dilation (expand the shapes), erosion (shrink the shapes), opening (dilation followed by\n",
    "erosion), and closing (erosion followed by dilation). Morphological operations are used to \n",
    "remove noise, separate objects, and connect objects in an image. \n",
    "\n",
    "**Further reading**:\n",
    "- OpenCV documentation. [Link](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html)\n",
    "- Beautiful illustration how morphological operations work: [Link](https://penny-xu.github.io/blog/mathematical-morphology)\n",
    "- Wikipedia article on mathematical morphology. [Link](https://en.wikipedia.org/wiki/Mathematical_morphology)\n",
    "- Blog post on morphological operations. [Link](https://towardsdatascience.com/7bcf1ed11756)\n",
    "\n",
    "###Â \\*\\* Distance transform\n",
    "The distance transform is useful for a variety of applications in image processing. It\n",
    "permits to compute the distance of each pixel to the nearest boundary in a binary image.\n",
    "Based on distance transforms, we can perform operations such as skeletonization, identify\n",
    "geometric properties of objects or segment images. The algorithm works by iteratively \n",
    "propagating the distance values from the boundary pixels to the interior pixels. The \n",
    "distance is computed using a metric such as the Euclidean distance. It is relatively \n",
    "cheap to compute the distance transform.\n",
    "\n",
    "**Further reading**\n",
    "- Another application of the distance transform (in combination with watershed). [Link](https://docs.opencv.org/3.4/d2/dbd/tutorial_distance_transform.html)\n",
    "\n",
    "\n",
    "### \\*\\*\\* Connected components\n",
    "Connected components in a binary image are regions of pixels that are touching each\n",
    "other. In image processing, connected components are used to identify single objects \n",
    "in a segmentation mask. The connected components algorithm works by labeling each\n",
    "pixel in the mask with a unique (integer) label based on the connectivity of the pixels. \n",
    "\n",
    "**Further reading**\n",
    "- Wikipedia article on connected component labeling. [Link](https://en.wikipedia.org/wiki/Connected-component_labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "img = img1\n",
    "\n",
    "# Implement the approach lined out above. You can copy paste the code \n",
    "# from the above link and plug our image into it. Try to understand the\n",
    "# code and the different steps. You may have to adjust the parameters\n",
    "# to get a good segmentation result.\n",
    "\n",
    "# https://docs.opencv.org/4.x/d3/db4/tutorial_py_watershed.html\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **AI driven segmentation**\n",
    "Nowadays, deep learning is often used for image segmentation. The U-Net\n",
    "architecture is a popular choice for this task. It is a convolutional\n",
    "neural network that is particularly well suited for segmentation tasks.\n",
    "The nnU-Net is a more advanced version of the U-Net that has been optimized\n",
    "for medical image segmentation, and comes with self-adapting preprocessing\n",
    "and postprocessing steps, where the network learns the optimal parameters\n",
    "for the task at hand. It is available as a Python package and can be installed\n",
    "via pip.\n",
    "\n",
    "Although machine learning / artificial intelligence is not the focus of this\n",
    "course, we can use such models to perform image segmentation. In contrast to \n",
    "the methods described above, deep learning models can learn the relevant \n",
    "features from the data and can generalize to unseen data. However, these methods\n",
    "require large amounts of labeled data for training, and are computationally\n",
    "more expensive. They are also often considered as \"black boxes\", as it is\n",
    "difficult to understand why the model makes a certain decision.\n",
    "\n",
    "```python\n",
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "```\n",
    "\n",
    "Visit the following resources and examine if they could be useful for your own segmentation project.\n",
    "- Segment anything by Meta AI. [Demo](https://segment-anything.com/demo), [Paper](https://arxiv.org/abs/2304.02643), [Code](https://github.com/facebookresearch/segment-anything) \n",
    "- Huggingface: Collection of public, pre-trained models. [Link](https://huggingface.co/spaces).\n",
    "  - Some models come with a demo interface. \n",
    "  - For instance, the background removal [RemBG](https://huggingface.co/spaces/KenjieDec/RemBG) tool is found there.\n",
    "  - Another popular segmentation tool is [Demo](https://huggingface.co/spaces/fcakyon/yolov8-segmentation), [Code](https://huggingface.co/spaces/fcakyon/yolov8-segmentation)\n",
    "  - To search the entire database for models: [Link](https://huggingface.co/models)\n",
    "- Total segmentator for anatomical CT data. [Demo](https://totalsegmentator.com/), [Paper](https://arxiv.org/abs/2208.05868), [Code](https://github.com/wasserth/TotalSegmentator)\n",
    "\n",
    "\n",
    "We have seen now a couple of approaches to segment images. How you can make best\n",
    "use of them depends on the specific problem and your engineering skills. ðŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

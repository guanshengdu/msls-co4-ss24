{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**\n",
    "\n",
    "Image preprocessing may involve resizing, cropping (or selection of a region of interest (ROI)), denoising, itensity or color adjustments, with the purpose of improving the quality of the image for further processing. Here we will use the OpenCV library to perform some of these operations.\n",
    "\n",
    "We will use hematological images displaying red blood cells and white blood cells\n",
    "from a blood smear. The red blood cells are colored in red, and the white blood cells are\n",
    "colored in blue / purple. The background is colored in white / gray. We will use the information\n",
    "contained in the color channels to later segment the different cells.\n",
    "\n",
    "![Hematology data](../data/images/hematology-collage.svg?1)\n",
    "\n",
    "The data suffers from several imperfections. The resolution is relatively low,\n",
    "the image is noisy, and displays image compression artifacts (blockiness), as \n",
    "the image was saved as a JPEG file. Furthermore, the blood cells are overlapping\n",
    "with each other, which makes it difficult to distinguish them.\n",
    "\n",
    "In this tutorial we will showcase different techniques to improve the quality\n",
    "of the image, such as:\n",
    "- Cropping\n",
    "- Resizing\n",
    "- Masking\n",
    "- Denoising\n",
    "- Enhancing contrast\n",
    "- Sharpening\n",
    "- (Removing artifacts)\n",
    "- Color conversion\n",
    "- Color correction / white balancing\n",
    "- Background removal\n",
    "\n",
    "Further reading: \n",
    "- Geeks for Geeks: Image Enhancement Techniques using OpenCV. [Link](https://www.geeksforgeeks.org/image-enhancement-techniques-using-opencv-python/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Preparations**\n",
    "\n",
    "Let's begin with some preparatory steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "#Â Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable this line if you want to use the interactive widgets\n",
    "# It requires the ipympl package to be installed.\n",
    "#%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "img1 = cv.imread(\"../data/images/hematology-baso1.jpg\", cv.IMREAD_COLOR)\n",
    "img2 = cv.imread(\"../data/images/hematology-baso2.jpg\", cv.IMREAD_COLOR)\n",
    "img3 = cv.imread(\"../data/images/hematology-blast1.jpg\", cv.IMREAD_COLOR)\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: OpenCV uses BGR color space by default. However, Matplotlib uses RGB color space.\n",
    "For consistency, we convert the images to RGB color space before displaying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "img3 = cv.cvtColor(img3, cv.COLOR_BGR2RGB)\n",
    "\n",
    "images = [img1, img2, img3]\n",
    "\n",
    "# Let's display the images\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will use several functions to display images.\n",
    "Before continuing, we quickly summarize some options we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain matplotlib\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\");   # Hide axes.\n",
    "\n",
    "# Based on Jupyter's display() function.\n",
    "tools.display_image(img1)\n",
    "\n",
    "# Show pairs of images\n",
    "tools.show_image_pair(img1, img2, title1=\"Baso 1\", title2=\"Baso 2\")\n",
    "\n",
    "# Show axes coordinates\n",
    "tools.show_image_pair(img1, img2, title1=\"Baso 1\", title2=\"Baso 2\", show_axes=True)\n",
    "\n",
    "# Show a chain of images\n",
    "tools.show_image_chain([img1, img2, img3], titles=[\"Baso 1\", \"Baso 2\", \"Blast 1\"])\n",
    "\n",
    "# Show a grid of images\n",
    "images_tmp = images*2\n",
    "titles = [\"Baso 1\", \"Baso 2\", \"Blast 1\"]\n",
    "titles *= 2\n",
    "tools.show_image_grid(images_tmp, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Cropping**\n",
    "\n",
    "Cropping an image means that we are selecting a rectangular region of interest (ROI) \n",
    "from the image. In Python, we can use the slicing operator to crop a region from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# Crop the image such that only the purple white blood cell is visible.\n",
    "# Use the slicing operator to crop the image. \n",
    "\n",
    "# Specify the coordinates of the bounding box\n",
    "xs, ys = 250, 160\n",
    "h, w = 100, 100\n",
    "\n",
    "# Crop the image with the slicing operator\n",
    "img1_crop = ...\n",
    "\n",
    "# Display the image\n",
    "tools.show_image_pair(img1, img1_crop, title1=\"Original\", title2=\"Cropped\", \n",
    "                      shape=None, box_aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Resizing**\n",
    "\n",
    "We can use OpenCVs [`resize()`](https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d) method to resample an image to a certain size. Note \n",
    "that we can both downsample (make the image smaller), or upsample (make it bigger). Note the \n",
    "argument `interpolation` which specifies the interpolation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Resize the image to half and double its size.\n",
    "img1_half = ...\n",
    "img2_double = ...\n",
    "\n",
    "tools.show_image_chain(images=[img1_half, img1, img2_double], \n",
    "                       titles=[\"Half\", \"Original\", \"Double\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Masking**\n",
    "\n",
    "With masking, we can separate a cell from the background, remove an artifact, or label a region as uninsteresting by setting it to zero. \n",
    "\n",
    "A mask is a binary image (with values True or False). If the mask has the same shape\n",
    "as the input image, it can be used to select pixels from the image and assign them \n",
    "to a new value. This is called masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# 1. Create a circular mask with the same size as the image.\n",
    "#    The center and the radius of the circle are provided below.\n",
    "#    You can use cv.circle() or define your own function.\n",
    "# 2. Apply the mask to the image img2.\n",
    "\n",
    "# Center and radius of the circle\n",
    "cx, cy = 220, 300\n",
    "r = 44\n",
    "\n",
    "# We use here a 2D binary mask\n",
    "mask = ...\n",
    "\n",
    "# Apply the mask to the RGB image, set all values to black\n",
    "\n",
    "# Visualize\n",
    "tools.show_image_pair(img2, img2_masked, title1=\"Original\", title2=\"Masked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Denoising**\n",
    "\n",
    "Several denoising methods are available. When denoising, one has to strike a balance between removing noise and preserving the details. The following methods are available in OpenCV:\n",
    "- Gaussian blur\n",
    "- Median blur\n",
    "- Bilateral filter\n",
    "\n",
    "Before continuing, read these OpenCV tutorials tutorials on [Smoothing](https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html) and [Image denoising](https://docs.opencv.org/4.x/d5/d69/tutorial_py_non_local_means.html)\n",
    "\n",
    "\n",
    "<!-- - Cropping\n",
    "- Resizing\n",
    "- Masking\n",
    "- Denoising\n",
    "- Enhancing contrast\n",
    "- Sharpening\n",
    "- (Removing artifacts)\n",
    "- Color conversion\n",
    "- Color correction / white balancing\n",
    "- Background removal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# 1. Apply Gaussian blur\n",
    "# 2. Apply median blur\n",
    "# 3. Apply bilateral filter (edge preserving)\n",
    "# 4. Apply a means denoising filter (second link)\n",
    "\n",
    "dst = ...\n",
    "tools.show_image_chain(images=[img1, dst], titles=[\"Original\", \"Denoised\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Sharpening**\n",
    "\n",
    "\n",
    "Sharpening refers to an operation that enhances the edges of an image.\n",
    "Two methods are commonly used: unsharp masking (related, high-boost filtering) and \n",
    "Laplacian sharpening. The former is based on subtracting a blurred version of the\n",
    "image from the original image, while the latter is based on applying a Laplacian\n",
    "filter to the image. \n",
    "\n",
    "Unsharp masking:\n",
    "1. Apply a Gaussian filter to the image.\n",
    "2. Subtract the filtered image from the original image.\n",
    "3. Add the result to the original image.\n",
    "\n",
    "Laplacian Filter\n",
    "- A second-order derivative operator/filter/mask. \n",
    "- Uses specific convolution kernels: [0 1 0; 1 -4 1; 0 1 0] or [-1 -1 -1; -1 8 -1; -1 -1 -1]\n",
    "- Note, the sum of the values of this filter is 0. \n",
    "- Apply using `cv.conv2(img, kernel, \"same\")``\n",
    "\n",
    "Further reading:\n",
    "- [Stackoverflow](https://stackoverflow.com/questions/4993082)\n",
    "- [Geeks for Geeks](https://www.geeksforgeeks.org/image-sharpening-using-laplacian-filter-and-high-boost-filtering-in-matlab/)\n",
    "\n",
    "\n",
    "<!-- - Cropping\n",
    "- Enhancing contrast\n",
    "- (Removing artifacts)\n",
    "- Color conversion\n",
    "- Color correction / white balancing\n",
    "- Background removal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXCERISE    ###\n",
    "######################\n",
    "\n",
    "# Implement one of the above methods to sharpen an image.\n",
    "kernel = ...\n",
    "img1_sharp = ...\n",
    "\n",
    "tools.show_image_pair(img1, img1_sharp, \n",
    "                      title1= \"Original\", \n",
    "                      title2=\"Sharpened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Color / intensity enhancements**\n",
    "\n",
    "Several methods based on histograms (histogram stretching, histogram equalization, or histogram matching) were demonstrated in the previous exercise.\n",
    "\n",
    "For certain types of adjustments, it makes sense to switch the color space.\n",
    "Notably, the HSV color space is often used to adjust the saturation and\n",
    "brightness of an image. Other color spaces (such as the YGrYb, L*a*b or Luv) separate luma (intensity)\n",
    "from chroma (color).\n",
    "\n",
    "\n",
    "<!-- - Cropping\n",
    "- Enhancing contrast\n",
    "- (Removing artifacts)\n",
    "- Color conversion\n",
    "- Color correction / white balancing\n",
    "- Background removal -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# Using the previous notebook 01-image-processing, \n",
    "# - increase the contrast in the image\n",
    "# - increase the saturation\n",
    "# - try to whiten the background, without losing the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Background removal**\n",
    "\n",
    "Background removal can be achieved by searching for the background color (thresholding)\n",
    "or background structure, or by using a segmentation technique to mask the foreground.\n",
    "\n",
    "We may be able to segment the background in the next notebook. For now, however, we can try to remove the background using a pre-trained model. Let's take a look at the [RemBG package](https://github.com/danielgatis/rembg). It uses a model convolutional neural net published on huggingface (see [here](https://huggingface.co/spaces/KenjieDec/RemBG)) to remove the background from images. The model does not work well with all images (it fails for our hematological images). But it may work with your images. Just try it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If rembg is not installed yet, uncomment the following line:\n",
    "#!pip install rembg\n",
    "\n",
    "from rembg import remove \n",
    "from PIL import Image \n",
    "\n",
    "# # RemBG requires a Pillow image as input. Let's\n",
    "# # convert the NumPy array into a Pillow image.\n",
    "# img_pil = Image.fromarray(img2) \n",
    "# # RemBG does not work for our dataset img1.\n",
    "# img_nobg = remove(img_pil) \n",
    "# tools.show_image_pair(np.asarray(img_pil), np.asarray(img_nobg), background_color=\"pink\")\n",
    "\n",
    "#Â But it works for other datasets.\n",
    "files = [ \"hematology-blast1.jpg\",\n",
    "          \"hematology-baso2.jpg\",\n",
    "          \"hematology-baso1.jpg\",\n",
    "          \"kingfisher.jpg\", \n",
    "          \"kingfisher-gray.jpg\", \n",
    "          \"histology-image.jpg\", \n",
    "          \"ct-brain-slices.jpg\" ]\n",
    "\n",
    "for f in files:\n",
    "    img_pil = Image.open(\"../data/images/\"+f)\n",
    "    img_nobg = remove(img_pil) \n",
    "    img_nobg.save(\"oink.png\")\n",
    "    tools.show_image_pair(np.asarray(img_pil), np.asarray(img_nobg), \n",
    "                          title1=f, title2=\"No background\",\n",
    "                          background_color=\"pink\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
